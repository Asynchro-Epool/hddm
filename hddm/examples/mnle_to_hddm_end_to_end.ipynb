{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sbi\n",
    "# !pip install cython\n",
    "# !pip install pymc==2.3.8\n",
    "# !pip install git+https://github.com/hddm-devs/kabuki\n",
    "# !pip install git+https://github.com/hddm-devs/hddm\n",
    "# !pip install git+https://github.com/AlexanderFengler/ssm_simulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import ssms\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sbi\n",
    "from sbi.inference import MNLE\n",
    "from sbi.inference import MCMCPosterior\n",
    "from ssms.basic_simulators import simulator\n",
    "import hddm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior\n",
    "m = torch.distributions.uniform.Uniform(low = torch.tensor(ssms.config.model_config['ddm']['param_bounds'][0]),\n",
    "                                        high = torch.tensor(ssms.config.model_config['ddm']['param_bounds'][1]))\n",
    "#Sample from the prior to collect theta matrix\n",
    "thetas = m.sample((100000,))\n",
    "#For every theta, draw 1 sample.\n",
    "x = ssms.basic_simulators.simulator(model = 'ddm', theta = thetas, n_samples = 1)\n",
    "#Format the output of the simulator\n",
    "x = torch.Tensor(np.hstack((x['rts'], x['choices'])))\n",
    "#Edit choices to [0,1] since that is the format MNLE expects.\n",
    "x[:,1] = (x[:,1] + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise prior\n",
    "prior = sbi.utils.BoxUniform(low=torch.tensor(ssms.config.model_config['ddm']['param_bounds'][0]), \n",
    "                             high=torch.tensor(ssms.config.model_config['ddm']['param_bounds'][1]), device = 'cuda')   \n",
    "#Initialise trainer and train on simulated data\n",
    "trainer = MNLE(prior=prior, device = 'cuda')\n",
    "trainer = trainer.append_simulations(thetas, x)\n",
    "mnle = trainer.train(training_batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedWrapper():\n",
    "    def __init__(\n",
    "        self, MixedDensityEstimator):\n",
    "        self.mde = MixedDensityEstimator\n",
    "        self.dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    def predict_on_batch(self, data):\n",
    "        #internally, data comes in the form [[theta | rt, choice]]. So to collect x we select the last two columns.\n",
    "        x = torch.tensor(data[:,-2:]).to(self.dev)\n",
    "        x[:,1] = (x[:,1] + 1)/2\n",
    "        #Select all but the last two columns to collect theta\n",
    "        theta = torch.tensor(data[:,:-2]).to(self.dev)\n",
    "        return self.mde.log_prob(x, theta).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise wrapper\n",
    "model_cust = MixedWrapper(MixedDensityEstimator = mnle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate testing data from a fixed theta.\n",
    "fixed_theta = torch.tensor([1.0, 1.5, 0.5, 0.5])\n",
    "sim_out = simulator(model = 'ddm', \n",
    "                    theta = fixed_theta,\n",
    "                    n_samples = 1000)\n",
    "#Edit output of simulator\n",
    "sim_out = torch.Tensor(np.hstack((sim_out['rts'], sim_out['choices'])))\n",
    "\n",
    "#Create a pandas in the format that HDDM wants\n",
    "theta_array = fixed_theta.repeat(1000,1)\n",
    "x = sim_out\n",
    "edited_choices = (x[:,1] + 1) / 2\n",
    "x = torch.tensor(np.vstack((x[:,0], edited_choices)).T)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(x).astype(\"float\")\n",
    "df.columns = ['rt', 'response']\n",
    "df['v']=theta_array[:,0]\n",
    "df['a']=theta_array[:,1]\n",
    "df['z']=theta_array[:,2]\n",
    "df['t']=theta_array[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit\n",
    "model_config = ssms.config.model_config['ddm']\n",
    "model_config[\"choices\"] = [1,0]\n",
    "\n",
    "hddmnn_model = hddm.HDDMnn(data = df,\n",
    "                           informative = False,\n",
    "                           include = model_config['hddm_include'],# Note: This include statement is an example, you may pick any other subset of the parameters of your model here\n",
    "                           model = 'ddm',\n",
    "                           model_config = model_config,\n",
    "                           network = model_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample from the model\n",
    "hddmnn_model.sample(700, burn = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the posteriors\n",
    "hddmnn_model.plot_posteriors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('hddmnn_tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff3096d2709bbb36a4584c44f6e6ffdb5e175071e94d34047f50b078bfdc1c6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
